{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bde3af0-8698-4a23-8320-9a0928c55c34",
   "metadata": {},
   "source": [
    "# BioGPT\n",
    "## Generative pre-trained transformer for biomedical text generation and mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5e882d-9981-40c8-b18f-3e754de6cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from fairseq.models.transformer_lm import TransformerLanguageModel\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785f2af1-c68d-4669-9122-4797c359ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = \"/opt/shared/data/biogpt/checkpoints\"\n",
    "data_path = \"/opt/shared/data/biogpt/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a419ff6-143a-4b06-b164-39d85810783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(model):\n",
    "    m = TransformerLanguageModel.from_pretrained(\n",
    "        os.path.join(checkpoints_path, model),\n",
    "        \"checkpoint.pt\",\n",
    "        os.path.join(data_path, model),\n",
    "        tokenizer='moses',\n",
    "        bpe='fastbpe',\n",
    "        bpe_codes=os.path.join(data_path, model, \"bpecodes\"),\n",
    "        min_len=100,\n",
    "        max_len_b=1024)\n",
    "    m.cuda()\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e044a14b-b378-40dd-8b28-1ca97f875959",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8f7abc-7b17-4a61-afe6-80dd1ef2c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, model):\n",
    "    global m\n",
    "    if m.get(model) == None:\n",
    "        print('Cold start. Loading the weights...')\n",
    "        m[model] = start(model)\n",
    "        print('GPU is running')\n",
    "    src_tokens = m[model].encode(prompt)\n",
    "    generate = m[model].generate([src_tokens], beam=5)[0]\n",
    "    output = m[model].decode(generate[0][\"tokens\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4e20f-5702-4298-bbc9-b034b8ee9fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def button_factory(text):\n",
    "    button = widgets.Button(\n",
    "        description=text,\n",
    "        disabled=False,\n",
    "        display='flex',\n",
    "        flex_flow='column',\n",
    "        align_items='stretch',\n",
    "        layout=layout\n",
    "    )\n",
    "    return button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823023dd-c32c-4e7a-a3e2-68bc9e6a06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = widgets.Layout(width='auto', height='40px') #set width and height\n",
    "\n",
    "inp = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type something',\n",
    "    description='Prompt:',\n",
    "    disabled=False,\n",
    "    display='flex',\n",
    "    flex_flow='column',\n",
    "    align_items='stretch',\n",
    ")\n",
    "button = widgets.Button(\n",
    "    description='Generate',\n",
    "    disabled=False,\n",
    "    tooltip='Click me',\n",
    "    icon='cog'\n",
    ")\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=['BioGPT', 'BioGPT-Large'],\n",
    "    value='BioGPT',\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    ")\n",
    "output = widgets.Output()\n",
    "response_widget = widgets.HTML(\n",
    "    value=\"\",\n",
    "    description='<b>></b>',\n",
    ")\n",
    "\n",
    "def btn_generate(btn):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        response_widget.value = '<img src=\"https://user-images.githubusercontent.com/3059371/49334754-3c9dfe00-f5ab-11e8-8885-0192552d12a1.gif\" width=\"50\" />'\n",
    "        text = generate(inp.value, model_dropdown.value)\n",
    "        clear_output()\n",
    "        response_widget.value = text\n",
    "\n",
    "button.on_click(btn_generate)\n",
    "\n",
    "search_bar = widgets.VBox([widgets.HBox([inp,button]), model_dropdown])\n",
    "\n",
    "suggestion_prompts = ['COVID-19 is', 'A 65-year-old female patient with a past medical history of']\n",
    "suggestion_buttons = [button_factory(prompt) for prompt in suggestion_prompts]\n",
    "\n",
    "def btn_populate_search_bar(btn):\n",
    "    inp.value = btn.description\n",
    "\n",
    "for btn in suggestion_buttons:\n",
    "    btn.on_click(btn_populate_search_bar)\n",
    "\n",
    "suggestions = widgets.HBox(suggestion_buttons)\n",
    "\n",
    "display(search_bar, suggestions, response_widget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Data Science 0.1.7",
   "language": "python",
   "name": "python-data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
